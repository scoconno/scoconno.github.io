---
layout: mindweekly
title: Notes

---


## Consciousness

Turing thought it obvious that the capacity to imitate a human was sufficient for a machine to enjoy mentality. It certainly is sufficient if mentality consists entirely in the abilty to ask questions, give answers, joke, tease, lament and symphatesize. In other words, if all there is to having a mind is the ability to hold a conversation, then machines could one day enjoy mentality (if they don't already). But Searle's thought experiment seems to show that there is something more to the mind than just the ability to have conversations; something that the machine is crucially lacking. At this point, it should seem no surprise to learn that many think that this missing ingredient is consciousness. And many claim that consciousness, whatever it is, is not something enjoyed by a machine regardless of how loquacious it may be. 

But why think that consciousness is not enjoyed by a machine? Isn't the machine aware of the people it is talking to? Isn't a robotic car aware of the obstacles it successfully navigates on the road? If being aware is sufficient for being conscious, then robotic cars are clearly conscious. In this section and the next, we will try get clearer on this question by asking about the nature of consciousness, what exactly is it that we take humans to possess and machines to lack? There are two distinct questions we will focus on:: 

1. What is consciousness? What are its features? How best can they be described?
2. How does consciousness come to exist? If from the brain, how so?

Our first question asks us to identify the defining features of consciousness. Should it be characterized as mere awareness of the external world? If not, what else is it? Is there just one phenomenon of consciousness or might there be several different phenomena that we use the same word to describe? If so, what are these different phenomena? 

Our second question asks how consciousness exists. The 19th century biologist puts the question as follows: 

> But what consciousness is, we know not; and how it is that anything so remarkable as a state of consciousness comes about as the result of irritating nervous tissue, is just as unaccountable as the appearance of the Djin when Aladdin rubbed his lamp in the story, or as any other ultimate fact of nature (Huxley). 

Humans are conscious and our consciousness has something to do with our brains. But what is that 'something'? Just how could a brain produce consciousness in the first place? This second question is, of course, related to the first. If we learn that there are, in fact, two types of consciousness, then we will need to determine how the brain gives rise to each type. We will focus on the second question in the next module. 


## “What Is It Like to Be a Bat?”

The entry point for our discussion is Thomas Nagel's seminal 1974 paper, "What is it like to be a bat?". The paper restored consciousness to a central problem in philosophy and neuroscience, for, as Nagel convinced us:

  > The most important and characteristic feature of conscious mental phenomena is very poorly understood (436).

In order to identify the features of consciousness, Nagel asks us to contrast conscious creatures from non-conscious creatures: 

![Animal Consciousness](animals.jpg)

![Alien Consciousness](Aliens.jpg)

![What is missing?](Zombies.jpg)

We likely agree that aleins and the more complex animals are conscious, whereas zombies would not be conscious. Nagel asks us to reflect on what makes the conscious creatures conscious, features that will be lacking in the zombie. He first observes the following: 

> It is not analyzable in terms of any explanatory system of functional states, or intentional states, since these could be ascribed to robots or automata that behaved like people though they experienced nothing (436).

We have already seen an argument like this from Searle. It doesn't seem that consciousness just consists in performing tasks because a non-conscious creature could easily do this. Instead, Nagel thinks that we can see from these examples that there is what he call  'what it's like' quality of consciousness. He uses bats to illustrate the point.  

![Echolocation](bat.jpg)

Bats are mammals, which seem to have conscious experience. They use echolocation to navigate and perceive objects. And, both sonar and vision are regarded as perceptional experiences. Nagel observes that what it's like to see a bug is probably different from what it's like to echolocate that bug. Similarly, what's it like to taste chocolate is different from what it is like to see chocolate. He infers from this that, in general, what it's like to a bat is different from what it's like to be a human.

The `what it is like' aspect to our mental lives seems mysterious. I don't have direct access to how you feel when you stub your toe. Likewise, you do not have direct access to how I feel when I stub my toe. The inability to properly appreciate others mental lives can be problematic. I once lectured while having a crushing headache. I grimaced and kept going, answering questions as best I could. Afterwards, a student asked me why I was so angry with them. That student believed something about my mental life, but that belief was wrong. Now, I tell students if I have a headache or if something else is affecting my performance. In more serious situations, our inability to reliably judge the subjective character of another person's experience can lead us to judge them poorly, e.g., a police officer might incorrectly judge a person to be relishing the news of someone's death, a protestor might judge a politician to feel hatred towards their group or cause. Nagel puts the point as follows: 

> The problem is not confined to exotic cases, however, for it exists between one person and another. The subjective character of the experience of a person deaf and blind from birth is not accessible to me, for example, nor presumably is mine to him. This does not prevent us each from believing that the other's experience has such a subjective character (440)

I am confident that your experiences have a subjective character. You too should be confident that my experiences too have a subjective character. But, we know this about each other without really knowing what that subjective character is like. If you think that Nagel is right about this, then you agree with him that he has isolated something important about consciousness: the subjective character of our experiences. 

## Qualia

“What it is like” refers to the specific qualitative character of experiences. An itch feels different from a tickle. A sharp pain feels different from a burning one. Thirst feels different from hunger. Seeing something that looks green is different from seeing something that looks blue. 'What it is like' refers to hurtfullness of the pain, the greenness of a visual experience, etc. The idea that your experiences have a 'what it is like' feel to them may be either mysterious or obvious to you. The only way I can prove that they do is by asking you to conduct a simple thought experiment with me. 

After closing your eyes and ignoring as much of the external worlds as possible, imagine a chili on your tongue. Now imagine a chocolate on your tongue. Think really hard about the difference in taste. What were you aware of? You were clearly aware of the chocolate and the chili. But, you were also aware of something else. You were aware of the taste of the chocolate and the taste of the chili; these tastes were different. It feels a certain way when you taste chocolate, and it feels a certain way when you taste a chili, and those two feelings are different. These differences are what we are talking about when we talk about the 'what it is like' aspect of our mental states.

Philosophers use different words for this feature our mental states. The most popular word is 'qualia', though the following are also used: 

1. Phenomenal properties
2. Phenomenological properties
3. Raw feels
4. What it's like

These terms are ways of getting you to identify something you are already familiar with it. They aren't meant to introduce you to something new. If you are not already familiar from your own mental life that mental states have a dis­tinctive feel, these words will mean nothing to you. The different feel that your states have are qualia, which seem essential to consciousness.
 
There is plenty of evidence for qualia. Consider first your experience of color:  

![Colors](figure1.gif)

It is tempting to think that your experience of color is to be explained fully in terms of the properties and features of what you see. You might think that the content of a color experience just is the external object and its features. But there seems to be something more to our experiences than the objects we experience and their properties. Imagine that a person, Ted, suffers an unusual brain injury. The parts of his brain responsible for vision inverts the colors of the objects they had experienced in the past: 

![Inverted](inverted.jpg)

Before Ted's accident, he placed a strawberry in his fridge. That strawberry appeared red to him. After the injury, he returns to the fridge and takes out the strawberry. But it now looks green to him! He is very unsettled by this. Green looks very different than red. Obviously, there is more to Ted's experience of the strawberry than just the external object. His perceptual experience of the strawberry has properties, perceptual properties, or qualia, that are different from the properties of the strawberry. These properties changed after the brain injury. The strawberries did not change. 

We don't need such a bizarre example to be convinced that there are qualia. Consider that sensational dress that caused such an internet outcry. What color is it? 

![What color is the dress?](dress.jpg)

Some were adamant that the dress was white and gold. Others were adamant that it was blue and black. Neither group would budge. Both groups saw the same dress, but the qualia of their relevant perceptions of the dress were different. 


## Types of consciousness

The notion of qualia, or "what it's like" allows us draw some interesting distinctions about consciousness. Consider this claim by Nagel: 

> fundamentally an organism has **conscious mental states** if and only if there is **something that it is like to *be* that organism**-something it is like *for* the organism (436)

Nagel in fact is really pointing to two phenomena. 1) What it is like to be a creature of a certain sort, and 2) what it's like to have a mental state of a certain sort. 

State Consciousness: 
: a state of a creature is conscious if there is something it is like to be in that state.

Some conscious states
1. Pain: there is something it is like to experience pain in a burned finger. 
2. Vision: there is something it is like to see a large red circle painted on a white wall.
3. Smell:  there is something it is like to smell a rotten egg. 

Some non-conscious states
1. Bodily states: there is nothing that is like to have hair grow (though there is something that is like to *feel* your hair grow. 
2. Your age and weight. 

Creature (subject) Consciousness: 
: A conscious creature is one that is capable of having conscious states.


## Phenomenal and Access Consciousness

Noticing that there are qualia allows us to raise interesting questions about consciousness and ask some pressing questions. Consider these two cases: 

**Blindsight**


https://www.youtube.com/watch?v=R4SYxTecL8E
https://www.youtube.com/watch?v=GwGmWqX0MnM

(**Some optional extras**)
+ https://www.youtube.com/watch?v=ny5qMKTcURE
+ http://www.bbc.com/future/story/20150925-blindsight-the-strangest-form-of-consciousness

**Subconscious Thought**
https://www.youtube.com/watch?v=SomZ6aViWGY

The first video discussed cases of blindsight. You may, for instance, place a ball in the sphere of some blind person's vision and ask them to grasp it with their hand. They claim they cannot see the ball, but they succeed in grasping it anyway. And their success matches the success of the sighted, e.g., they grasp the ball as quickly and as reliably as those with vision grasp it. The second video introduce us to cases of subconscious thoughts. While driving to school or work with a friend, we may not be consciously focusing on the road. Nevertheless, we navigate the obstacles as if we were focusing like a new driver. We adjust our speed to the cars around us. We steer to avoid a pothole. But if anyone asked you what you were thinking about, you would respond that your mind was on the conversation. 

What is going on in both these cases? Ned Block has introduced the following important distinction: 

> Phenomenal consciousness is experience; what makes a state phenomenally conscious is that there is something “it is like” to be in that state (Block, “On a Confusion about a Function of Consciousness”, p.377)

A mental state is phenomenally conscious, then, just if it has qualia. This contrasts to the following: 

> A state is A-conscious [access-conscious] if it is poised for direct control of thought and action. To add more detail, a representation is [access]-conscious if it is poised for free use in reasoning and for direct “rational” control of action, and speech. An [access-conscious] state is one that consists in having an [access-conscious] representation (Block, “On a Confusion about a Function of Consciousness,”, p. 382.).

When you notice the swerving car, you can complain about that car to your friend. Since you were able to do something with the awareness of the car, i.e., think and talk about that car's behavior, your thought of that car is a-conscious (as well as p-conscious). So, a thought is a-conscious if it is broadcast to the creatures brain. Such thoughts are posed to interact with a wide variety of the creature's other thoughts and to directly drive its behavior. Access conscious thoughts are usually the ones you can report if someone were to ask you, what are you thinking now? 

There are three ways of relating access consciousness (a-consciousness) and phenomenal consciousness (p-consciousness). 

1. A-consciousness together with p-consciousness, e.g., driving successfully, you are p-conscious of the cars and report their behavior to your friend. 
2. P-consciousness without a-consciousness, e.g., driving successfully, you are p-conscious of the cars, but do not actively think about or report their behavior to your friend. Instead, you talk about your latest philosophy course. 
2. A-consciousness without p-consciousness, e.g., driving successfully, the robot car reports the behavior of the other cars to the neural network. But the robot car is not p-conscious of its surroundings. 

## Blindsight

Return now to our problematic cases. Blindsight is a case where you have a-consciousness without p-consciousness. How might this happen? The human visual system is divided into two separate subsystems - the ventral and dorsal subsystems. 

![Ventral and dorsal subsystems](dorsal.jpg)


The ventral system is responsible for object recognition and classification. It is responsible for recognizing that an object is a chair as opposed to a dolphin, a tree as opposed to a building, etc. The dorsal system is is responsible for recognizing spatial features such as location and motion, e.g., for recognizing that the dog is moving and that the dog is closer to us than the cat. Block associates P-consciousness with the ventral system. It's noticeable that in blindsight there seems to be damage to the ventral system.

Of course, you might claim that these people don't have a-consciousness of the stimuli in their blind region. Blindsight patients must be prompted by an experimenter before they will 'take a guess'. But Block asks us to imagine a super-blindsighter who had acquired the ability to guess when to guess about the content of her blind field. Even though she doesn't see the objects in her blind field, she can spontaneously offer verbal reports about those objects. Information about her blind field just spring into her thoughts. A super-blindsighter would be a-conscious but not p-conscious.




## P-consciousness without A-consciousness

**Case 1: Damage**

Suppose the damage occurred the other way. That there was damage to the dorsal system, but not the ventral system. Block believes that in such cases we would have f P-Consciousness without A-Consciousness. Unlike the blindsight case, though, note that the person with p but not a conscious would not be able to report to us what they are p-conscious about. Lacking a-Consciousness implies that the content of the p-conscious state is not available for rational manipulation, including reporting things like "I see a blue goose". 

**Case 2: subconscious thoughts**

Our subconscious experiences have qualia and they may even cause us to behave in certain ways. But these subconscious states are not available for direct rational control. They are not immediately available for us to deliberate about and knowingly act upon. So even if they effect our behavior, they do not do so in the same way our rational deliberation effects our behavior. These states then are p-conscious without being a-conscious. Some of these states can, of course, become a-conscious. For instance, perhaps the sound of a jackhammer has caused you to grimace as you were absorbed in a good book. You didn't realize you were grimacing and you didn't give any of your attention to that noise. But once you put down the book, you might notice that you are grimacing and the cause is that noise. You can then deliberate about whether to call in a noise complaint, shut the window, or leave the house. In this case, you become a-conscious of the state that was previously causing your grimace. 

https://www.youtube.com/watch?v=UYSKW3IvZlQ
 

Do animals have phenomenal consciousness without access consciousness? 







