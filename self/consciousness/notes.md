---
layout: mindweekly
title: Notes

---


## Consciousness

The remainder of this course will focus on consciousness, whose importance we can highlight by considering our last two topics. 



*Functionalism* 

Turing thought it obvious that the capacity to imitate a human was sufficient for a machine to enjoy mentality. It certainly is sufficient if mentality consists entirely in the ability to ask questions, give answers, joke, tease, and sympathize. In other words, if all there is to having a mind is the ability to hold a conversations, then machines could one day enjoy mentality (if they don't already). But Searle's thought experiment seemed to show that there is something more to the mind than just the ability to have conversations; something that machines are crucially lacking. At this point, it should be no surprise to learn that many think that this missing ingredient is consciousness. And many claim that consciousness, whatever it is, is not something enjoyed by a machine regardless of how loquacious it may be. 



*Epiphenomenalism*

If every physical effect has a sufficient physical cause, it seems that mental states must either be causally inert or nothing more than physical states. The latter is the view of the psycho-neural identity theory of mind. The former is the view of the epiphenomenalists, who claim that only the body has causal powers and the mind is causally inert. On their view, we are akin to passengers in our bodies unable to influence or control it (even though we might delude ourselves that we can.) Again, it should be no surprise to learn that consciousness has been seen as key to deciding between these views. Consciousness, we will see, is difficult to describe in purely physical terms, and there are good reasons to think it is irreducible to any physical state. 



So what is consciousness? Why think that consciousness is not enjoyed by a machine? Isn't the machine aware of the people it is talking to? Isn't a robotic car aware of the obstacles it successfully navigates? If being aware is sufficient for being conscious, then robotic cars are clearly conscious. In the remainder of the course, we will try get clearer on this question by asking about the nature of consciousness, what exactly is it that we take humans to possess and machines to lack? There are two distinct questions we will focus on: 

1. What is consciousness? What are its features? How best can they be described?
2. How does consciousness come to exist? If from the brain, how so?

Our first question asks us to identify the defining features of consciousness. Should it be characterized as mere awareness of the external world? If not, what else is it? Is there just one phenomenon of consciousness or might there be several different phenomena that we use the same word to describe? If so, what are these different phenomena? Consider how we use the adjective 'conscious' and noun 'consciousness':

1. 'The cat is conscious of the mouse': here 'conscious' means something like being aware of.
2. 'The patient regained consciousness after the operation': here 'consciousness' means something like being awake.
3. 'Paul was acutely conscious of himself when walking on stage': here 'conscious' means something like self-conscious. 
4. 'Gandhi was a supremely conscious being': here 'conscious' means something like being the type of thing that can enjoys a wide range of conscious mental states. When I say that a stone is not conscious, I mean it is not awake, conscious of itself, the world, or anything else. 
5. 'My desire for success was not really conscious for a long time': here conscious describes a mental state. Some states are conscious mental states. Others are not conscious mental states. 

These are just a few examples, but they are sufficient to threaten the idea that consciousness is some single unified concept. 

Our second question asks how consciousness exists. A 19th century biologist puts the question as follows: 

> But what consciousness is, we know not; and how it is that anything so remarkable as a state of consciousness comes about as the result of irritating nervous tissue, is just as unaccountable as the appearance of the Djin when Aladdin rubbed his lamp in the story, or as any other ultimate fact of nature (Huxley). 

Humans are conscious and our consciousness has something to do with our brains. But what is that 'something'? Just how could a brain produce consciousness in the first place? This second question is related to the first. If we learn that there are, in fact, two types of consciousness, then we will need to determine how the brain gives rise to each type. We will focus on the second question later in the semester. Our focus now is the first question. 






## “What Is It Like to Be a Bat?”

Contemporary philosophers have primarily focused on why and how some mental states are conscious ones while others are not. Why is the taste of pepper in my mouth now a conscious state, while the sensation in my toes is (not currently) one? 

The entry point for our discussion is Thomas Nagel's seminal 1974 paper, "What is it like to be a bat?". The paper restored consciousness to a central problem in philosophy and neuroscience, for, as Nagel convinced us:

  > The most important and characteristic feature of conscious mental phenomena is very poorly understood (436).

In order to identify the features of consciousness, Nagel asks us to contrast conscious creatures from non-conscious creatures: 

![Animal Consciousness](animals.jpg)

![Alien Consciousness](Aliens.jpg)





## Zombies!



![What is missing?](Zombies.jpg)

We likely agree that aliens and the more complex animals are conscious whereas zombies are not. Zombies! Unfortunately, we won't be discussing the Walking Dead. Philosophers mean something very specific by 'zombie'. Recall the claim that all physical effects have a sufficient physical cause, one of the core claims that led to epiphenomenalism. This is a core principle of natural science, and it must be true of us if we can be studied by a science like neuroscience, e.g., if flinching from heat does not have a physical cause, like some characteristic neural firings, then obviously no natural science can determine what causes that reaction. The epiphenomenalist argues that consciousness has no role in this causal story; it is not my being conscious of the pain that causes the reaction. But if consciousness plays no causal role in our behavior, then it seems in principle possible that there could exist physical duplicates of us that lack consciousness. If epiphenomenalism is true, then: 

> it ought to be quite credible that the constitution and course of nature would be otherwise just the same as it is if there were not and never had been any experiencing individuals. Human bodies would still have gone through the motions of making and using bridges, telephones and telegraphs, of writing and reading books, of speaking in Parliament, of arguing about materialism, and so on. There can be no doubt that this is *prima facie* incredible to Common Sense (G. F Stout (1931) 138f.).


In other words, it seems the epiphenomenalist must allow for what are now called zombies. Such creatures are exact duplicates of us. What do I mean by duplicate? Imagine a possible world populated by our zombie doppelgängers. They look like us, behave like us, and are built exactly like us. There is zombie doppelgänger of you, a different zombie doppelgänger of Beyonce, a different one for Nancy Pelosi, etc. In this world, my zombie doppelgänger wrote an exact copy of this paragraph. When he did so, the neural pattern that caused his hand to type the letters is exactly the same as the neural pattern that caused me to type these letters. But there is a difference: I am conscsious while the zombie me is not. My body has a conscious passenger 'watching' how his body behaves and believing that he controls it. But the body of my zombie-me has no such conscious passenger. The epiphenomenalist should allow that this is conceivable, for, after all, they think that mental states have no causal role to play.  If mental states are completely redundant in explaining what we do and say, it seems possible that there are physical duplicates of us with no mental states whatsoever.


## What do zombies lack? 



Nagel asks us to reflect on what makes the conscious creatures conscious, features that will be lacking in the zombies. He first observes the following: 

> It is not analyzable in terms of any explanatory system of functional states, or intentional states, since these could be ascribed to robots or automata that behaved like people though they experienced nothing (436).

We have already seen an argument like this from Searle. It doesn't seem that consciousness just consists in carrying out various functions. Computers, robots, and zombies could do that without being conscious. Nagel thinks that we can see from these examples that there is what he calls a *what it's like* quality of consciousness, something our zombies lack. He uses bats to illustrate the point.  

![Echolocation](bat.jpg)

Bats are mammals that seem to have conscious experience. They use echolocation to navigate and perceive objects. But while their sonar and our vision are perceptional experiences, Nagel observes that what it's like to see a bug is probably different from what it's like to echolocate that bug. Similarly, what it is like to taste chocolate is different from what it is like to see chocolate. Nagel infers from this that, in general, what it's like to be a bat is different from what it's like to be a human.

The what it is like aspect to our mental lives seems mysterious. I don't have direct access to how you feel when you stub your toe. Likewise, you do not have direct access to how I feel when I stub my toe. The inability to properly appreciate others' mental lives can be problematic. I once lectured while having a crushing headache. I grimaced and kept going, answering questions as best I could. Afterwards, a student asked me why I was so angry. That student believed something about my mental life, but that belief was wrong. Now, I tell students if I have a headache or if something else is affecting me. In more serious situations, our inability to reliably judge the subjective character of another person's experience can lead us to judge them poorly, e.g., a police officer might incorrectly judge a person to be relishing the news of someone's death, a protestor might mistakingly judge a politician to feel hatred towards their group or cause, etc.

I imagine that you too can give examples of when someone was aware *that* your experience had a subjective character, but they mis-characterized that subjective character. Likewise, you should be willing to grant that we can reliably judge that creatures have subjective characters to their experiences without being confident about what that subjective character is. Nagel puts the point as follows: 

> The problem is not confined to exotic cases, however, for it exists between one person and another. The subjective character of the experience of a person deaf and blind from birth is not accessible to me, for example, nor presumably is mine to him. This does not prevent us each from believing that the other's experience has such a subjective character (440)

I am confident that your experiences have a subjective character. You too should be confident that my experiences have a subjective character. But we know this about each other without really knowing what that subjective character is like. This inability tells us something deeply important about consciousness. If Nagel is right, he has isolated something important about consciousness: there is a subjective character of our experiences. This is something that we enjoy but is crucially lacking in our zombie doppelgängers. 







## Qualia

The phrase 'what it is like' refers to this specific qualitative character of our experiences. An itch feels different from a tickle. A sharp pain feels different from a burning one. Thirst feels different from hunger. Seeing something that looks green is different from seeing something that looks blue. 'What it is like' refers to the hurtfulness of the pain, the greenness of a visual experience, etc. The idea that your experiences have a 'what it is like' feel to them may be either mysterious or obvious to you. The only way I can prove that they do is by asking you to conduct a simple thought experiment with me. 

After closing your eyes and ignoring as much of the external world as possible, imagine a chili on your tongue. Now imagine some chocolate on your tongue. Think really hard about the difference in taste. What were you aware of? You were clearly aware of the chocolate and the chili. But you were also aware of something else. You were aware of the taste of the chocolate and the taste of the chili; these tastes were different. It feels a certain way when you taste chocolate. It feels a certain way when you taste a chili. But those two feelings are different. These differences are what we are talking about when we talk about the 'what it is like' aspect of our mental states.

Philosophers use different words for this feature of our mental states. The most popular word is 'qualia', though the following are also used: 

1. Phenomenal properties
2. Phenomenological properties
3. Raw feels
4. What it's like

These terms are ways of getting you to identify something you are already familiar with it. They aren't meant to introduce you to something new. If you are not already familiar from your own mental life that mental states have a distinctive feel, these words will mean nothing to you. But none of you are zombies, so I am confident that your various states do feel different to you. The different feels that your states have are qualia, which we will see seems essential to consciousness.

There is plenty of evidence for qualia. Consider first your experience of color:  

![Colors](figure1.gif)

It is tempting to think that your experience of color is to be explained fully in terms of the properties and features of what you see. You might think that the content of a color experience just is the external object and its features. But there seems to be something more to our experiences than the objects we experience and their properties. Imagine that a person, Ted, suffers an unusual brain injury. The parts of his brain responsible for vision inverts the colors of the objects they had experienced in the past: 

![Inverted](inverted.jpg)

Before Ted's accident, he placed a strawberry in his fridge. That strawberry appeared red to him. After the injury, he returns to the fridge and takes out the strawberry. But it now looks green to him! He is very unsettled by this. Green looks very different from red. This shows that there is more to Ted's experience of the strawberry than just the external object. The object remained the same, but his perception of the object changed. This shows that his perceptual experience of the strawberry has properties, perceptual properties, or qualia, that are different from the properties of the strawberry. These properties changed after the brain injury, while the properties of the strawberries remained the same. 

We don't need such a bizarre example to be convinced that there are qualia. Consider that sensational dress that caused such an internet outcry. What color is it? 

![What color is the dress?](dress.jpg)

Some were adamant that the dress was white and gold. Others were adamant that it was blue and black. Neither group would budge. Both groups saw the same dress, but the qualia of their relevant perceptions of the dress were different. 

 

## Phenomenal and Access Consciousness
The notion of qualia is key to understanding contemporary debates about the nature of consciousness. Consider this claim by Nagel: 

> fundamentally an organism has conscious mental states if and only if there is something that it is like to be that organism-something it is like for the organism (436).

So, according to Nagel, what it means to be conscious just is to have mental states with qualia. Anything with qualia is conscious. Anything without qualia is not conscious.  But is this all there is to consciousness? Many have thought that it cannot be sufficient for the kind of consciousness that humans enjoy, which they think is the core notion of consciousness they are interested in. Let us assume that there is something that it is like to be a bat. Is this sufficient for bats to be self-aware? If not, and if self-awareness is key to consciousness, then Nage has identified a necessary but not sufficient component of consciousness. 

We are going to start our discussion of this question by distinguishing two types of consciousness: 

**Blindsight**

<iframe width="560" height="315" src="https://www.youtube.com/embed/R4SYxTecL8E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<iframe width="560" height="315" src="https://www.youtube.com/embed/GwGmWqX0MnM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



**Some optional extras**

+ [https://www.youtube.com/watch?v=ny5qMKTcURE](https://www.youtube.com/watch?v=ny5qMKTcURE)
+ [http://www.bbc.com/future/story/20150925-blindsight-the-strangest-form-of-consciousness](http://www.bbc.com/future/story/20150925-blindsight-the-strangest-form-of-consciousness)

**Subconscious Thought**

+ [https://www.youtube.com/watch?v=SomZ6aViWGY
](https://www.youtube.com/watch?v=SomZ6aViWGY)

The first set of videos discussed blindsight. You may place a ball in the sphere of some blind person's vision and ask them to grasp it with their hand. They claim they cannot see the ball, but they succeed in grasping it anyway. And their success matches the success of the sighted, e.g., they grasp the ball as quickly and as reliably as those with vision grasp it. The second type of video introduces us to cases of subconscious thoughts. While driving to school or work with a friend, we may not be consciously focusing on the road. Nevertheless, we navigate the obstacles as if we were focusing like a new driver. We adjust our speed to the cars around us. We steer to avoid a pothole. But if anyone asked you what you were thinking about, you would respond that your mind was on the conversation. 

What is going on in both these cases? Ned Block has introduced the following important distinction: 

> Phenomenal consciousness is experience; what makes a state phenomenally conscious is that there is something “it is like” to be in that state (Block, “On a Confusion about a Function of Consciousness”, p.377).

A mental state is phenomenally conscious, then, just if it has qualia. This contrasts to access consciousness:  

> A state is A-conscious [access-conscious] if it is poised for direct control of thought and action. To add more detail, a representation is [access]-conscious if it is poised for free use in reasoning and for direct “rational” control of action, and speech. An [access-conscious] state is one that consists in having an [access-conscious] representation (Block, “On a Confusion about a Function of Consciousness,”, p. 382.).

When you notice the swerving car, you can complain about that car to your friend. Since you were able to do something with the awareness of the car, i.e., think and talk about that car's behavior, your thought of that car is a-conscious (as well as p-conscious). So, a thought is a-conscious if it is broadcast to the creature's brain. Such thoughts are posed to interact with a wide variety of the creature's other thoughts and to directly drive its behavior. Access conscious thoughts are usually the ones you can report if someone were to ask you, 'what are you thinking now?' 

There are three ways of relating access consciousness (a-consciousness) and phenomenal consciousness (p-consciousness). 

1. A-consciousness together with p-consciousness, e.g., driving successfully, you are p-conscious of the cars and report their behavior to your friend. 
2. P-consciousness without a-consciousness, e.g., driving successfully, you are p-conscious of the cars, but do not actively think about or report their behavior to your friend. Instead, you talk about your latest philosophy course. 
2. A-consciousness without p-consciousness, e.g., driving successfully, the robot car reports the behavior of the other cars to the neural network. But the robot car is not p-conscious of its surroundings. 

## Blindsight

Return now to our problematic cases. Blindsight is a case where you have a-consciousness without p-consciousness. How might this happen? The human visual system is divided into two separate subsystems---the ventral and dorsal subsystems. 

![Ventral and dorsal subsystems](dorsal.jpg)


The ventral system is responsible for object recognition and classification. It is responsible for recognizing that an object is a chair as opposed to a dolphin, a tree as opposed to a building, etc. The dorsal system is responsible for recognizing spatial features such as location and motion, e.g., for recognizing that the dog is moving and that the dog is closer to us than the cat. Block associates P-consciousness with the ventral system. It's noticeable that in blindsight there seems to be damage to the ventral system.

Of course, you might claim that these people don't have a-consciousness of the stimuli in their blind region. Blindsight patients must be prompted by an experimenter before they will 'take a guess'. But Block asks us to imagine a super-blindsighter who has acquired the ability to guess when to guess about the content of her blind field. Even though she doesn't see the objects in her blind field, she can spontaneously offer verbal reports about those objects. Information about her blind field just spring into her thoughts. A super-blindsighter would be a-conscious without being p-conscious.


## P-consciousness without A-consciousness

**Case 1: Damage**

Suppose the damage occurred the other way, that there was damage to the dorsal system, but not the ventral system. Block believes that in such cases we would have p-consciousness without a-consciousness. Unlike the blindsight case, note that the person with p-consciousness and no a-consciousness would not be able to report to us what they are p-conscious about. Lacking a-consciousness implies that the content of the p-conscious state is not available for rational manipulation, including reporting things like "I see a blue goose". 

**Case 2: subconscious thoughts**

Our subconscious experiences have qualia and they may even cause us to behave in certain ways. But these subconscious states are not available for direct rational control. They are not immediately available for us to deliberate about and knowingly act upon. So even if they effect our behavior, they do not do so in the same way our rational deliberation effects our behavior. These states are p-conscious without being a-conscious. Some of these states can, of course, become a-conscious. For instance, perhaps the sound of a jackhammer has caused you to grimace as you were absorbed in a good book. You didn't realize you were grimacing and you didn't give any of your attention to that noise. But once you put down the book, you might notice that you are grimacing and the cause is that noise. You can then deliberate about whether to call in a noise complaint, shut the window, or leave the house. In this case, you become a-conscious of the state that was previously causing your grimace. 

https://www.youtube.com/watch?v=UYSKW3IvZlQ








