---
layout: mindweekly
title: Notes

---

## Review

Let us take stock. We have reviewed three theories of mind so far: 

Dualism:
: mental states are separate from brain states, e.g., pain is not identical to any brain state. 

Behaviorism: 
: mental states are identical to sets of behaviors and physiological responses, e.g., pain is identical to some behavior like grimacing and groaning. 

Identity Theory:
: mental states are identical to brain states, e.g., pain is identical to some brain state like c-fibers firing. 

We saw that dualists struggle to explain mental causation, to explain how the mind causes our bodies to move. We saw that the identity theorist has little difficulty explaining mental causation but does struggle to explain how all the properties of our minds could really be properties of our brain. And we saw that the behaviorist struggles to explain several features of mentality, including how mental states figure in the explanation of our behaviors. 

## Functional Definitions
Our final theory of mind is called **functionalism**. It is currently the most popular of the various theories. Functionalism hopes to accommodate the strengths of all our previous theories while avoiding their weaknesses. We will define functionalism as follows: 

Functionalism: 
: mental states are defined by the causal roles they play in the cognitive system as a whole, i.e., what it is to be a particular mental state just is to bring about some result given some input.

Let's unpack this definition. What does it mean to define something by a causal role? There are many functions and roles that entities play. For example, every job has a description, e.g., what it is to be a full time professor is to *conduct research in a field*, *teach courses in a field*, and *contribute to the running of a department, college, and university*. Each of these italicized phrases describe jobs of the full time professors. Different job titles exist: contingent faculty teach courses in their fields but do not contribute to the running of their department, college, and university. 

Take a moment and consider any job you have had. Write out what *work* that job required of you; that description is a definition of your job's function. Notice that the definition does not include what you must wear or what time you must start; these are not part of the work you do. They may be requirements of the job, but they are not what defines the job. What defines the job is the work that it requires of you. We will see that the functionalist believes that mental states must be understood in terms of the work they do.   

It can be difficult to identify functional definitions if phrases and terms admit of both a functional and non-functional definition. Consider hearts. What are they? You likely would  give one of two types of answers: 

Functional Definition:
: To be a heart is to pump oxygenated blood to the tissues and deoxygenated blood to the lungs. 

Material Definition: 
: To be a heart is to be a hollow muscular organ that has four chambers with two atria and two ventricles.

Our first definition describes the job that hearts perform. It makes no mention about the structure of the heart, about its parts and the materials it is constituted from. But the second definition **only** mentions the structure and constitution of the heart, while it says nothing about the job of the heart. 

Which of these two definitions states the true nature of the heart? A functionalist about hearts claims it is the first. They believe this because they think that all of the following count equally as hearts:

![image](hearts.jpg)

Each item is composed of different materials. Some are composed of tissues. Others are composed of metals and plastics. But each of these entities can pump oxygenated blood to the tissues and deoxygenated blood to the lungs. According to the functionalist, since each plays the role described in the functional definition of a heart, they are each hearts. So regardless of what an entity is made of, the functionalist about hearts claims  that it is a heart if it does the job of a heart. 

You shouldn't find this surprising. A person counts as occupying a position at a company if they do the work associated with that position. They do not count as occupying the position because they have blood and tissue as parts, or because they have a certain height, weight, or appearance. Such considerations do not define a job; it's the work that defines the job and people of varying heights, weights, and appearance can do it.

## Functionalism
The functionalist thinks that we need to be similarly careful to distinguish between functional and physical descriptions of mental states. The identity theorist, for instance,  thinks that mental states are defined by some physical description; they think that a mental state is identical to some brain state. But the functionalist disagrees. They think that the nature of a mental state is the job it plays; the nature of a mental state is defined by a functional role and not what constitutes it. 

Consider pain. What is pain's job? That might seem an odd question. Sure pain just feels, well, painful. It doesn't seem to be characterized by a job in the way our organs are. But there is more to pain than just the sensation. Pain states really do have a functional role, a role that even has a rich evolutionary history. Namely, when your body detects tissue damage, pain is that mental state that causes you to respond appropriately, e.g., it causes you to remove your hand from the burning object. Consider this image: 

![image](toe.gif) 

Upon stubbing his toe, this man winces and groans. The behaviorist thinks that this is all there is to pain. But the functionalist believes that pain is distinct from the winces and groans. She claims that pain's job is to cause this behaviors upon tissue being damaged. 

On this view, the pain state exists and is defined by the job that it does. It is, then, distinct from any behavior. Rather, pain is whatever causes you to behave in some distinctive way upon the detection of tissue damage. Pain is also distinct from any physical state. Just as what it is to be heart is not to be made of tissues, so too what it is to be pain is not to be made of some physical state. A physical state can play the role of pain just as some tissue can play the role of a heart. But the job and the thing that performs the job are distinct from one another. 

If functionalism is correct, then there is some role that each mental state plays. David Armstrong puts the point as follows: 

> the concept of a mental state is the concept of an internal state apt to be caused by certain sensory inputs and apt to cause certain behavioral outputs. A specification of input and output, <i, o>, will define a particular mental state: for example, <tissue damage, aversive behavior> defines pain, <skin irritation, scratching> defines itch, and so on.

So, each mental state will have some input and some output. The job of the mental state is to cause the output given the relevant input. The inputs can include other mental states. For instance, one of the inputs, or conditions, relevant in describing the role of being itchy might be that you are awake, where being awake is a mental state; you can't be itchy if you are asleep. The outputs too can include other mental states. Perhaps one of the outputs of belief is desire, e.g., a belief that eating kale is healthy might cause in you a desire to eat kale. 

Functionalists say that for every functionally defined mental state, there is something that plays the role given in the definition. We will say that any entity that plays the role *realizes* it. Kim's explanation is as follows: 

> F is a functional property (or kind) just in case F can be characterized by a definition of the following form: For something x to have F (or to be an F) = def for x to have some property P such that C(P), where C(P) is a specification of the causal work that P is supposed to do in x.

*And*

> Let F be a functional property defined by a functional definition, as above. Property Q is said to realize F, or be a realizer or a realization of F, in system x if and only if C(Q), that is, Q fits the specification C in x (which is to say, Q in fact performs the specified causal work in system x).

This is less complicated than it appears. Consider some examples: 

+ x is a mousetrap if x has some property P such that P enables x to trap and hold or kill mice.
+ x is a bread knife if x has some property P such that P enables x to cut bread. 
+ x is a heart if x has some property P such that P enables x to pump blood. 
+ x is a pain state if x has some property P such that P enables x to detect tissue damage and cause aversive behavior. 

So there are two things to keep clearly before us. The first is the functional definition of whatever we are interested in. The second is the properties something must possess to allow it play the relevant role. In the case of mental states, the functionalist claims that 1) each mental state has a specific functional definition, and 2) brain states have properties that allow them perform the job specified in these description of mental states. But note that 1) and 2) do not entail that brain states are identical to mental states. 1) and 2) only entail that brain states can do the work of mental states, but they leave open whether something other than brain states might also do the work. Consider this image of a function machine: 

![image](machine.gif)

There is some input and some output. There is also what causes the output given that input. In this case, it is the cogs that play this role. They have those features that allow it realize the role of causing the output given the input. But the role is not the same as the cogs. The cogs do the work, but they aren't identical to that work. We could imagine building the machine with different materials and still ensuring that the output is caused given the relevant input. 


## Argument for Functionalism

If functionalism is true, very different types of entities could realize the same role. Just as both plastic and organic materials can realize the role of a heart, different types of things could realize pain. All that is required is that they have some property that allows them to do the job specified in the functional description of pain.

A popular argument for functionalism is motivated by the conviction that a sufficiently complex computer program could realize various mental states. Since a computer is made of silicon and our brains are not, if a computer realizes some similar mental states as our brain does, then mental states cannot be identical to any of these physical states. Rather, mental states would be identical to various jobs or functions. Those jobs would be played by neurons in us and some silicon chips in a computer. 

You may not be surprised that computers are appealed to when investigating the mind. Whether it is Alexa or Siri, we regularly interact with apparently artificially intelligent machines. But a word of caution before we proceed. 'Artificial intelligence' could be understood in different ways when thinking about the mind. John Searle distinguished the following two claims:  

Weak Artificial Intelligence (WAI):
: Computers give us a powerful tool to study the mind. Thinking may be modeled by formal symbol systems, such as computer programs.

Strong Artificial Intelligence (SAI):
: Thinking is constituted by the manipulation of formal symbols, such as occurs in a computer program

WAI does not say that the computers really have minds. It says only that such machines might resemble minds, and they may provide us tools for investigating the mind by, for instance, giving us models that approximate the way the mind operates. But WAI does not say that computers have mental states; it does not say that states of the computer have properties that allow those states perform the job of any mental state. On this view, Siri and Alexa mimic what minds can do, but our iPhones and Amazon devices do not have mental states just by having Siri and Alexa on them.  So, WAI cannot be used to support functionalism. And, we might observe, WAI doubts the radical claims that computers might one day have mental lives akin to our own. On the other hand, SAI would give strong support for functionalism. If what it is to think just is to manipulate formal symbols, then thinking is a collection of functionally defined states. And, if such functions can be performed by both computers and human brains, then functionalism will be vindicated.  

## The Turing Test


![image](turing.jpg)



The best argument that machines, in principle, could eventually think comes from the Cambridge mathematician, Alan Turing. Turing is the parent of computer science and lived a truly remarkable life. During World War II, he worked at the Government Code and Cypher School in Bletchley Park and was key to breaking the German naval Enigma. In 1952, he was prosecuted for homosexuality, chemically castrated, and died in 1954 by suicide. In 2013, the British government righted this historic wrong and gave him a posthumous pardon.

Turing was interested in the question whether machines can think. He observed that it is difficult to define 'thought', so it is difficult to answer the question. Nevertheless, he pointed out that we have no difficulty agreeing that other humans think, and he suggested that whatever evidence we have that some human can think should allow us determine if machines can think. In other words, Turing believed we can investigate whether machines can do whatever that thing is that when done by us shows we have thought.  What might such evidence of thought be? According to Turing, it is being able to hold a sufficiently intelligent conversation. Since I can have an intelligent conversation with you, I know that you can think. If a computer could have a sufficiently intelligent conversation, then it too could think.   Thus, Turing devises his famous Imitation Game, or what is now called  the Turing Test, for intelligence. Kim's explanation: 

> The idea is that if machines can do as well as humans on certain cognitive, intellectual tasks, then they must be judged no less psychological (“intelligent”) than humans. What, then, are these tasks? Obviously, they must be those that, intuitively, require intelligence and mentality to perform. Turing describes a game, the “imitation game,” to test for the presence of these capacities.



## Test 1: Man or Woman

There are two tests we will perform. The first asks whether a computer could fool a person into thinking it was male. The second asks whether a computer could fool a person into thinking it was human.  

![image](2.jpg)

We will first develop a control test with three players: an interrogator, a man, and a woman. Each is in their own separate room. The man and woman are known only as “X” and “Y” to the interrogator. The interrogator asks them questions via keyboards and monitors. Each player has a distinct task: 

1. Interrogator: identify the sex of X and Y. 
1. Man: mislead the interrogator to make a false identification
2. Woman: help the interrogator make the correct identification. 

Our interrogators can ask any questions they like. They could ask, for instance, 'are you male or female?'. The man will do whatever he can to make the interrogator judge incorrectly. The woman will do whatever she can to help the interrogator judge correctly. There are no restrictions on the topics of the questions asked; the interrogator can ask anything. 

Suppose that we randomly select 1000 people to serve as interrogators and use that to decide how likely it is that someone can make the correct identification. Suppose 70% of our interrogators are tricked by the man; they judge incorrectly. Turing now asks us to replace the man with a machine, a machine which has been programmed to trick the interrogator into making the wrong guesses. If the machine consistently tricks interrogators into misidentifying it or the woman, then Turing claims that the machine is intelligent. In other words, if a machine can cause an interrogator to wrongly identify it to the same  degree that an ordinary human could, then it is as intelligent as an ordinary human. 

## Test 2: Human or not? 

![image](3.jpg)

In our second test, our interrogators are told that they are talking to one computer and one human, and they have to judge correctly who is who. The roles of our participants are slightly different: 

1. Interrogator: determine which of X and Y is the computer and which is the human. 
2. Computer: cause the interrogator to judge incorrectly, i.e., cause the interrogator into thinking that the computer is, in fact, a human. 
3. Human: aid the interrogator into making the correct judgement. 

Our interrogator will again ask questions and have a rich conversation. Will they be able to identify the computer? Or will the computer be able to consistently fool them into thinking that they, the computer, is human?  If a computer can consistently fool us, then Turing believed that the machine has the kind of mentality that we grant to humans. And, even if machines aren't sufficiently complex to do so now, Turing wrote: 


> I believe that in about fifty years’ time it will be possible to program computers...to make them play the imitation game so well that an average interrogator will not have more than 70 percent chance of making the right identification after five minutes of questioning...I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted. (Alan Turing)

How does all this provide evidence for functionalism? Understanding a sentence is a mental state. And, according to the functionalist, this mental state has a functional role, a job to play: it disposes the entity who possess that state to respond in various ways given certain inputs. For instance, understanding the question 'where were you from?' disposes me to answer that 'I was born in Dublin.' Understanding does clearly have a job in conversations, and Turing's simple idea is that anything that can perform the job of understanding has understanding. Let us present this idea in argument form:  

1. For some arbitrary time period, there is no discernible difference between the linguistic behavior of a person and that of a machine.
2. If there is no discernible difference in linguistic behavior between man and machine, then there is no difference in the causes of that behavior.
3. Therefore, if understanding is the cause of the linguistic behavior in the person, understanding is the cause of the linguistic behavior in the machine.

It's a brilliant argument. If machines can do whatever mentality allows us to do, then machines must also have mentality. 

## Clarifying the Turing Test
I want to make one clarifying remark about the Turing Test: Distinguish these two questions: 

1. Is passing the Turing Test *necessary* for intelligence?
2. Is passing the Turing Test *sufficient* for intelligence?

Turing believes that the answer to both these questions in 'yes', but it is important to understand what that amounts to. Roughly, to say that passing the test is necessary for intelligence means that it is impossible to be intelligent without the ability to pass the test. This does not mean that passing the test is enough for intelligence. Perhaps more is required. But it does mean that  the ability to pass the test is required. In contrast, to say that passing the test is sufficient for intelligence is to say that passing the test all by itself is enough for intelligence. Nothing else is required. Pass it and the machine is intelligent. But this does not mean that passing the test would be required for intelligence. 

Confusing? The reason is that necessary and sufficient conditions are themselves confusing. Formally, we can present the difference as follows: 

P is necessary for Q:
:  Q entails P.

P is sufficient for Q:
:   P entails Q.

Here are some examples: having access to a snowboard is necessary for competing in the snowboard contests at the Olympics; you cannot compete in that competition without a snowboard. But having access to a snowboard is not sufficient. If it were, then anyone without a snowboard could compete in the Olympics. But that's not the case. You must also win a variety of qualifying competitions as well as many other requirements. 

In contrast, passing all the requirements to compete in a the snowboard contest at the Olympics is sufficient for being an Olympic contestant. If you enter as a member of the snowboard team, you are in the Olympics. You do not need to do anything else to become a contestant. But, passing all the requirements to compete as a snowboarder is not necessary for competing in the Olympics: you could become a Olympic contestant by  passing the requirements for, say, downhill skiing or ice-skating. So, metaphorically, think of alternative sufficient conditions in terms of roads to the same city. If there are multiple roads, there can be several roads you can take to the one city. If there is only one possible road to the city, then that road provides a necessary and sufficient route to the city; you must take that road, and if you take it, you will get there. 

One more example: being an unmarried man is necessary *and* sufficient for being a bachelor. Being unmarried is itself necessary for being a bachelor, but not sufficient. There are many unmarried people who are not bachelors, e.g., unmarried women. Being a man is also necessary for being a bachelor, but it again not itself sufficient. There are many men who are not bachelors, e.g., married men. In contrast, being an unmarried man is both necessary and sufficient for being a bachelor; anyone who is a bachelor is an unmarried man, and anyone who is an unmarried man is a bachelor. 

Still don't get it? These videos from Wireless Philosophy have some nice visual aids: 

<iframe width="560" height="315" src="https://www.youtube.com/embed/5LqNm9d2__I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<iframe width="560" height="315" src="https://www.youtube.com/embed/9uOF3AZI_Gc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

According to Turing, the ability to pass the Turing Test is both necessary and sufficient for intelligence. If anything passes the test, it is intelligent. If anything is unable to pass the test, it is not intelligent. Pause on this for a moment. Turing does not claim that the ability to the pass the test is one of several important elements to intelligence. He claims that it is the only element; it is by itself sufficient for intelligence. Turing also does not say that passing the test is one way of being intelligent, with other possible routes available. He claims that the only way to be intelligent is having the ability to pass this test. 

Turing's main claim may appear radical, but it is precisely the type of claim a functionalist is committed to. They claim that each mental state has a unique job. Anything that does that job realizes the mental state. And there is no other way of realizing the mental state other than by doing that job. If, then, the job of intelligence is responding appropriately when asked various questions, to carry out conversations, then 1) anything which does that job is intelligent, and 2) there is no other way of being intelligent than by doing that job.

*...next time: problems with the Turing Test...*